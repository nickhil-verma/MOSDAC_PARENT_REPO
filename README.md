 
# ğŸ›°ï¸ MOSDAC_PARENT_REPO

This is the central control hub for the **MOSDAC scraping ecosystem**, combining multiple repositories and tools for intelligent data scraping, AI processing (via Ollama + Gemma/LLaMA 3), and API access.

---

## ğŸ“¦ Repository Structure

### ğŸ”— Linked Repositories

- ğŸ” [`MOSDAC_SCRAPPING_SCRIPT`](https://github.com/Hireonova/MOSDAC_SCRAPPING_SCRIPT)  
  Python-based web scraper using Playwright + BeautifulSoup. Feeds data to LLMs (Gemma/LLaMA 3 via Ollama).

- âš™ï¸ [`MOSDAC_EXPRESS_API`](https://github.com/Hireonova/MOSDAC_EXPRESS_API)  
  Express.js backend API for serving processed job listings or any other scraped output from MongoDB.

---

## ğŸ§  Features

- ğŸ§¹ Clean, modular structure with separation of scraper + API
- âš¡ GitHub push automation for updating sub-repos with one command
- ğŸŒ RESTful API endpoints to serve AI-processed results
- ğŸ§  Integrates with Ollama to feed scraped data to local Gemma/LLaMA models
- ğŸ¥ YouTube demo coming soon

---

## ğŸš€ Quick Start

### ğŸ“ 1. Clone the Parent Repo

```bash
git clone --recurse-submodules https://github.com/Hireonova/MOSDAC_PARENT_REPO.git
cd MOSDAC_PARENT_REPO
````

> If you didnâ€™t use `--recurse-submodules`:

```bash
git submodule update --init --recursive
```

---

### ğŸ“¤ 2. Push All Repos at Once (Script Provided)

A helper script `push_all.sh` is included to commit and push all changes from the parent and sub-repos.

```bash
bash push_all.sh "Your commit message"
```

> ğŸ” Ensure your Git credentials are cached or SSH keys are set up.

---

### ğŸ§ª 3. Run Express API Locally

```bash
cd MOSDAC_EXPRESS_API
npm install
npm start
```

API will be served at: [http://localhost:5000](http://localhost:5000)

---

### ğŸ“¡ 4. Run Python Scraper + LLM

```bash
cd MOSDAC_SCRAPPING_SCRIPT
python main.py
```

Make sure:

* Ollama is running locally
* `.env` file is configured with Mongo URI + model info

---

## ğŸ¬ YouTube Demo

[![Watch the Demo Video](https://img.youtube.com/vi/oXbNl3tMYuc/hqdefault.jpg)](https://youtu.be/oXbNl3tMYuc?si=JhL7lzNYiVs90Oz5)

ğŸ“º A full walkthrough of the scraping, LLM processing, and API system in action.


* Real-time scraping
* LLM-based job matching
* MongoDB integration
* API usage

Stay tuned and subscribe for updates!

---

## ğŸ§© Tech Stack

* **Python** â€” Playwright, BeautifulSoup, LangChain
* **Node.js / Express** â€” API handling
* **MongoDB** â€” Central data storage
* **Ollama + Gemma 3 / LLaMA 3** â€” Local AI inference

---

 
 
